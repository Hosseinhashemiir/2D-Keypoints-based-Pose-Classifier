{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_X(X_path):\n",
    "    file = open(X_path, 'r')\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',') for row in file\n",
    "        ]], \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    file.close()\n",
    "    return X_\n",
    "\n",
    "def load_Y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]], \n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(a, b):\n",
    "    # This function calculates the euclidean distance between 2 point in 2-D coordinates\n",
    "    # if one of two points is (0,0), dist = 0\n",
    "    # a, b: input array with dimension: m, 2\n",
    "    # m: number of samples\n",
    "    # 2: x and y coordinate\n",
    "    try:\n",
    "        if (a.shape[1] == 2 and a.shape == b.shape):\n",
    "            # check if element of a and b is (0,0)\n",
    "            bol_a = (a[:,0] != 0).astype(int)\n",
    "            bol_b = (b[:,0] != 0).astype(int)\n",
    "            dist = np.linalg.norm(a-b, axis=1)\n",
    "            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n",
    "    except:\n",
    "        print(\"[Error]: Check dimension of input vector\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_X(X):\n",
    "    num_sample = X.shape[0]\n",
    "    # Keypoints\n",
    "    Nose = X[:,0*2:0*2+2]\n",
    "    Neck = X[:,1*2:1*2+2]\n",
    "    RShoulder = X[:,2*2:2*2+2]\n",
    "    RElbow = X[:,3*2:3*2+2]\n",
    "    RWrist = X[:,4*2:4*2+2]\n",
    "    LShoulder = X[:,5*2:5*2+2]\n",
    "    LElbow = X[:,6*2:6*2+2]\n",
    "    LWrist = X[:,7*2:7*2+2]\n",
    "    RHip = X[:,8*2:8*2+2]\n",
    "    RKnee = X[:,9*2:9*2+2]\n",
    "    RAnkle = X[:,10*2:10*2+2]\n",
    "    LHip = X[:,11*2:11*2+2]\n",
    "    LKnee = X[:,12*2:12*2+2]\n",
    "    LAnkle = X[:,13*2:13*2+2]\n",
    "    REye = X[:,14*2:14*2+2]\n",
    "    LEye = X[:,15*2:15*2+2]\n",
    "    REar = X[:,16*2:16*2+2]\n",
    "    LEar = X[:,17*2:17*2+2]\n",
    "\n",
    "    # Length of head\n",
    "    length_Neck_LEar = euclidean_dist(Neck, LEar)\n",
    "    length_Neck_REar = euclidean_dist(Neck, REar)\n",
    "    length_Neck_LEye = euclidean_dist(Neck, LEye)\n",
    "    length_Neck_REye = euclidean_dist(Neck, REye)\n",
    "    length_Nose_LEar = euclidean_dist(Nose, LEar)\n",
    "    length_Nose_REar = euclidean_dist(Nose, REar)\n",
    "    length_Nose_LEye = euclidean_dist(Nose, LEye)\n",
    "    length_Nose_REye = euclidean_dist(Nose, REye)\n",
    "    length_head      = np.maximum.reduce([length_Neck_LEar, length_Neck_REar, length_Neck_LEye, length_Neck_REye, \\\n",
    "                                 length_Nose_LEar, length_Nose_REar, length_Nose_LEye, length_Nose_REye])\n",
    "    #length_head      = np.sqrt(np.square((LEye[:,0:1]+REye[:,0:1])/2 - Neck[:,0:1]) + np.square((LEye[:,1:2]+REye[:,1:2])/2 - Neck[:,1:2]))\n",
    "\n",
    "    # Length of torso\n",
    "    length_Neck_LHip = euclidean_dist(Neck, LHip)\n",
    "    length_Neck_RHip = euclidean_dist(Neck, RHip)\n",
    "    length_torso     = np.maximum(length_Neck_LHip, length_Neck_RHip)\n",
    "    #length_torso     = np.sqrt(np.square(Neck[:,0:1]-(LHip[:,0:1]+RHip[:,0:1])/2) + np.square(Neck[:,1:2]-(LHip[:,1:2]+RHip[:,1:2])/2))\n",
    "\n",
    "    # Length of right leg\n",
    "    length_leg_right = euclidean_dist(RHip, RKnee) + euclidean_dist(RKnee, RAnkle)\n",
    "    #length_leg_right = np.sqrt(np.square(RHip[:,0:1]-RKnee[:,0:1]) + np.square(RHip[:,1:2]-RKnee[:,1:2])) \\\n",
    "    #+ np.sqrt(np.square(RKnee[:,0:1]-RAnkle[:,0:1]) + np.square(RKnee[:,1:2]-RAnkle[:,1:2]))\n",
    "\n",
    "    # Length of left leg\n",
    "    length_leg_left = euclidean_dist(LHip, LKnee) + euclidean_dist(LKnee, LAnkle)\n",
    "    #length_leg_left = np.sqrt(np.square(LHip[:,0:1]-LKnee[:,0:1]) + np.square(LHip[:,1:2]-LKnee[:,1:2])) \\\n",
    "    #+ np.sqrt(np.square(LKnee[:,0:1]-LAnkle[:,0:1]) + np.square(LKnee[:,1:2]-LAnkle[:,1:2]))\n",
    "\n",
    "    # Length of leg\n",
    "    length_leg = np.maximum(length_leg_right, length_leg_left)\n",
    "\n",
    "    # Length of body\n",
    "    length_body = length_head + length_torso + length_leg\n",
    "    \n",
    "    # Check all samples have length_body of 0\n",
    "    length_chk = (length_body > 0).astype(int)\n",
    "    \n",
    "    # Check keypoints at origin\n",
    "    keypoints_chk = (X > 0).astype(int)\n",
    "    \n",
    "    chk = length_chk * keypoints_chk\n",
    "    \n",
    "    # Set all length_body of 0 to 1 (to avoid division by 0)\n",
    "    length_body[length_body == 0] = 1\n",
    "    \n",
    "    # The center of gravity\n",
    "    # number of point OpenPose locates:\n",
    "    num_pts = (X[:, 0::2] > 0).sum(1).reshape(num_sample,1)\n",
    "    centr_x = X[:, 0::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "    centr_y = X[:, 1::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "\n",
    "    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n",
    "    X_norm_x = (X[:, 0::2] - centr_x) / length_body\n",
    "    X_norm_y = (X[:, 1::2] - centr_y) / length_body\n",
    "    \n",
    "    # Stack 1st element x and y together\n",
    "    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1]))\n",
    "        \n",
    "    for i in range(1, X.shape[1]//2):\n",
    "        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1]))\n",
    "    \n",
    "    # Set all samples have length_body of 0 to origin (0, 0)\n",
    "    X_norm = X_norm * chk\n",
    "    \n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(a, b):\n",
    "    if (a.any()> 0 and b.any()>0): plt.plot([a[0], b[0]], [a[1], b[1]], 'k-')\n",
    "        \n",
    "def plot_skeleton(sample, pattern):\n",
    "    for i in range(len(sample)//2):\n",
    "        plt.plot(sample[i*2], sample[i*2+1], pattern) \n",
    "    skeleton = sample.reshape(1, 36)\n",
    "    Nose = skeleton[:,0*2:0*2+2][0]\n",
    "    Neck = skeleton[:,1*2:1*2+2][0]\n",
    "    RShoulder = skeleton[:,2*2:2*2+2][0]\n",
    "    RElbow = skeleton[:,3*2:3*2+2][0]\n",
    "    RWrist = skeleton[:,4*2:4*2+2][0]\n",
    "    LShoulder = skeleton[:,5*2:5*2+2][0]\n",
    "    LElbow = skeleton[:,6*2:6*2+2][0]\n",
    "    LWrist = skeleton[:,7*2:7*2+2][0]\n",
    "    RHip = skeleton[:,8*2:8*2+2][0]\n",
    "    RKnee = skeleton[:,9*2:9*2+2][0]\n",
    "    RAnkle = skeleton[:,10*2:10*2+2][0]\n",
    "    LHip = skeleton[:,11*2:11*2+2][0]\n",
    "    LKnee = skeleton[:,12*2:12*2+2][0]\n",
    "    LAnkle = skeleton[:,13*2:13*2+2][0]\n",
    "    REye = skeleton[:,14*2:14*2+2][0]\n",
    "    LEye = skeleton[:,15*2:15*2+2][0]\n",
    "    REar = skeleton[:,16*2:16*2+2][0]\n",
    "    LEar = skeleton[:,17*2:17*2+2][0]\n",
    "    #Nose = sample.reshape(1, 36)[:,0*2:0*2+2][0]\n",
    "    #Neck = sample.reshape(1, 36)[:,1*2:1*2+2][0]\n",
    "    plot_line(LEar, LEye)\n",
    "    plot_line(LEye, Nose)\n",
    "    plot_line(REar, REye)\n",
    "    plot_line(REye, Nose)\n",
    "    plot_line(Nose, Neck)\n",
    "    plot_line(Neck, LShoulder)\n",
    "    plot_line(LShoulder, LElbow)\n",
    "    plot_line(LElbow, LWrist)\n",
    "    plot_line(Neck, RShoulder)\n",
    "    plot_line(RShoulder, RElbow)\n",
    "    plot_line(RElbow, RWrist)\n",
    "    plot_line(Neck, LHip)\n",
    "    plot_line(LHip, LKnee)\n",
    "    plot_line(LKnee, LAnkle)\n",
    "    plot_line(Neck, RHip)\n",
    "    plot_line(RHip, RKnee)\n",
    "    plot_line(RKnee, RAnkle)\n",
    "    \n",
    "def plot(sample):\n",
    "    # sample is one-dimension array\n",
    "    # e.g: (36,)\n",
    "    if sample.shape[0] == 36:\n",
    "        sample_norm = norm_X(sample.reshape(1,36))[0]\n",
    "\n",
    "        # Plot original coordinates\n",
    "        pad_ori = 40\n",
    "        plt.figure(str(sample))\n",
    "        plt.subplot(121)\n",
    "        plt.title('Original skeleton')\n",
    "        X_ori = sample\n",
    "        x_max = max(X_ori[0::2]) + pad_ori\n",
    "        x_min = min(i for i in X_ori[0::2] if i > 0) - pad_ori\n",
    "        y_max = max(X_ori[1::2]) + pad_ori\n",
    "        y_min = min(j for j in X_ori[1::2] if j > 0) - pad_ori\n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_max, y_min)\n",
    "        plot_skeleton(X_ori, 'bo')\n",
    "\n",
    "        # Plot normalized coordinates\n",
    "        pad_nor = 0.2\n",
    "        #plt.figure(2)\n",
    "        plt.subplot(122)\n",
    "        plt.title('Normalized skeleton')\n",
    "        X_nor = sample_norm\n",
    "        x_max = max(X_nor[0::2]) + pad_nor\n",
    "        x_min = min(X_nor[0::2]) - pad_nor\n",
    "        y_max = max(X_nor[1::2]) + pad_nor\n",
    "        y_min = min(X_nor[1::2]) - pad_nor\n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_max, y_min)\n",
    "        plot_skeleton(X_nor, 'ro')\n",
    "    else:\n",
    "        print(\"sample is one-dimension array: (36,)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                2368      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 5,027\n",
      "Trainable params: 5,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='sigmoid', input_shape=(36,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# plot training log\n",
    "def plot_history(history):\n",
    "    history_dict = history.history\n",
    "    history_dict.keys()\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # \"bo\" is for \"blue dot\"\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    # b is for \"solid blue line\"\n",
    "    plt.plot(epochs, val_loss, 'ro', label='Validation loss')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and norminalize dataset\n",
    "X_train = load_X('dataset/X_train.txt')\n",
    "Y_train = load_Y('dataset/Y_train.txt')\n",
    "X_train_norm = norm_X(X_train)\n",
    "\n",
    "X_test = load_X('dataset/X_test.txt')\n",
    "Y_test = load_Y('dataset/Y_test.txt')\n",
    "X_test_norm = norm_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2676 samples, validate on 701 samples\n",
      "Epoch 1/500\n",
      "2676/2676 [==============================] - 0s 112us/step - loss: 1.1003 - acc: 0.3950 - val_loss: 0.9536 - val_acc: 0.6020\n",
      "Epoch 2/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.8848 - acc: 0.5665 - val_loss: 0.6796 - val_acc: 0.6976\n",
      "Epoch 3/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.7090 - acc: 0.6790 - val_loss: 0.5164 - val_acc: 0.7889\n",
      "Epoch 4/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.6227 - acc: 0.7250 - val_loss: 0.4572 - val_acc: 0.8074\n",
      "Epoch 5/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.5488 - acc: 0.7821 - val_loss: 0.3901 - val_acc: 0.8616\n",
      "Epoch 6/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.5090 - acc: 0.8087 - val_loss: 0.3222 - val_acc: 0.8930\n",
      "Epoch 7/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.4872 - acc: 0.8195 - val_loss: 0.2891 - val_acc: 0.9016\n",
      "Epoch 8/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.4445 - acc: 0.8427 - val_loss: 0.2766 - val_acc: 0.9016\n",
      "Epoch 9/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.4241 - acc: 0.8501 - val_loss: 0.2651 - val_acc: 0.9016\n",
      "Epoch 10/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.4318 - acc: 0.8457 - val_loss: 0.2601 - val_acc: 0.9044\n",
      "Epoch 11/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3936 - acc: 0.8651 - val_loss: 0.2492 - val_acc: 0.9073\n",
      "Epoch 12/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3855 - acc: 0.8610 - val_loss: 0.2323 - val_acc: 0.9116\n",
      "Epoch 13/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3989 - acc: 0.8647 - val_loss: 0.2351 - val_acc: 0.9130\n",
      "Epoch 14/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.3889 - acc: 0.8666 - val_loss: 0.2346 - val_acc: 0.9158\n",
      "Epoch 15/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3810 - acc: 0.8528 - val_loss: 0.2298 - val_acc: 0.9130\n",
      "Epoch 16/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3780 - acc: 0.8700 - val_loss: 0.2245 - val_acc: 0.9144\n",
      "Epoch 17/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.3568 - acc: 0.8662 - val_loss: 0.2295 - val_acc: 0.9201\n",
      "Epoch 18/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3518 - acc: 0.8763 - val_loss: 0.2354 - val_acc: 0.9187\n",
      "Epoch 19/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3520 - acc: 0.8670 - val_loss: 0.2233 - val_acc: 0.9158\n",
      "Epoch 20/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.3625 - acc: 0.8729 - val_loss: 0.2174 - val_acc: 0.9201\n",
      "Epoch 21/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3497 - acc: 0.8894 - val_loss: 0.2186 - val_acc: 0.9201\n",
      "Epoch 22/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3408 - acc: 0.8812 - val_loss: 0.2132 - val_acc: 0.9158\n",
      "Epoch 23/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.3569 - acc: 0.8853 - val_loss: 0.2226 - val_acc: 0.9144\n",
      "Epoch 24/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3480 - acc: 0.8812 - val_loss: 0.2149 - val_acc: 0.9201\n",
      "Epoch 25/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3471 - acc: 0.8913 - val_loss: 0.2183 - val_acc: 0.9173\n",
      "Epoch 26/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3283 - acc: 0.8860 - val_loss: 0.2235 - val_acc: 0.9230\n",
      "Epoch 27/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3383 - acc: 0.8857 - val_loss: 0.2166 - val_acc: 0.9130\n",
      "Epoch 28/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3126 - acc: 0.8946 - val_loss: 0.2283 - val_acc: 0.9244\n",
      "Epoch 29/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.3266 - acc: 0.8976 - val_loss: 0.2230 - val_acc: 0.9116\n",
      "Epoch 30/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.3298 - acc: 0.8924 - val_loss: 0.2044 - val_acc: 0.9144\n",
      "Epoch 31/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3228 - acc: 0.8924 - val_loss: 0.2156 - val_acc: 0.9101\n",
      "Epoch 32/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.3277 - acc: 0.8905 - val_loss: 0.2203 - val_acc: 0.9116\n",
      "Epoch 33/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3222 - acc: 0.8871 - val_loss: 0.2079 - val_acc: 0.9144\n",
      "Epoch 34/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.3059 - acc: 0.9032 - val_loss: 0.2087 - val_acc: 0.9215\n",
      "Epoch 35/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3221 - acc: 0.8984 - val_loss: 0.2009 - val_acc: 0.9272\n",
      "Epoch 36/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.3210 - acc: 0.8924 - val_loss: 0.1956 - val_acc: 0.9173\n",
      "Epoch 37/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.3084 - acc: 0.9043 - val_loss: 0.2154 - val_acc: 0.9158\n",
      "Epoch 38/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2843 - acc: 0.9066 - val_loss: 0.2022 - val_acc: 0.9201\n",
      "Epoch 39/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.3121 - acc: 0.8969 - val_loss: 0.2030 - val_acc: 0.9173\n",
      "Epoch 40/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.3198 - acc: 0.8946 - val_loss: 0.2102 - val_acc: 0.9230\n",
      "Epoch 41/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.3090 - acc: 0.9002 - val_loss: 0.2004 - val_acc: 0.9244\n",
      "Epoch 42/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2986 - acc: 0.9028 - val_loss: 0.1984 - val_acc: 0.9230\n",
      "Epoch 43/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.3072 - acc: 0.8995 - val_loss: 0.1960 - val_acc: 0.9173\n",
      "Epoch 44/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2969 - acc: 0.9017 - val_loss: 0.1789 - val_acc: 0.9158\n",
      "Epoch 45/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2841 - acc: 0.9021 - val_loss: 0.1870 - val_acc: 0.9201\n",
      "Epoch 46/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2942 - acc: 0.9028 - val_loss: 0.1975 - val_acc: 0.9173\n",
      "Epoch 47/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2910 - acc: 0.9084 - val_loss: 0.1791 - val_acc: 0.9244\n",
      "Epoch 48/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2744 - acc: 0.9103 - val_loss: 0.1819 - val_acc: 0.9244\n",
      "Epoch 49/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2724 - acc: 0.9107 - val_loss: 0.1807 - val_acc: 0.9258\n",
      "Epoch 50/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2879 - acc: 0.9073 - val_loss: 0.1773 - val_acc: 0.9244\n",
      "Epoch 51/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2838 - acc: 0.9051 - val_loss: 0.1754 - val_acc: 0.9158\n",
      "Epoch 52/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2740 - acc: 0.9099 - val_loss: 0.1753 - val_acc: 0.9372\n",
      "Epoch 53/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2709 - acc: 0.9118 - val_loss: 0.1760 - val_acc: 0.9415\n",
      "Epoch 54/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2731 - acc: 0.9129 - val_loss: 0.1714 - val_acc: 0.9444\n",
      "Epoch 55/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2779 - acc: 0.9073 - val_loss: 0.1696 - val_acc: 0.9415\n",
      "Epoch 56/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2706 - acc: 0.9114 - val_loss: 0.1679 - val_acc: 0.9458\n",
      "Epoch 57/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2554 - acc: 0.9193 - val_loss: 0.1732 - val_acc: 0.9429\n",
      "Epoch 58/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2535 - acc: 0.9178 - val_loss: 0.1653 - val_acc: 0.9429\n",
      "Epoch 59/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2598 - acc: 0.9096 - val_loss: 0.1591 - val_acc: 0.9429\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2743 - acc: 0.9144 - val_loss: 0.1658 - val_acc: 0.9472\n",
      "Epoch 61/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2541 - acc: 0.9170 - val_loss: 0.1660 - val_acc: 0.9401\n",
      "Epoch 62/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2614 - acc: 0.9159 - val_loss: 0.1672 - val_acc: 0.9444\n",
      "Epoch 63/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2545 - acc: 0.9230 - val_loss: 0.1681 - val_acc: 0.9472\n",
      "Epoch 64/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2555 - acc: 0.9155 - val_loss: 0.1610 - val_acc: 0.9444\n",
      "Epoch 65/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2544 - acc: 0.9189 - val_loss: 0.1610 - val_acc: 0.9372\n",
      "Epoch 66/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2701 - acc: 0.9148 - val_loss: 0.1559 - val_acc: 0.9401\n",
      "Epoch 67/500\n",
      "2676/2676 [==============================] - 0s 55us/step - loss: 0.2602 - acc: 0.9159 - val_loss: 0.1564 - val_acc: 0.9444\n",
      "Epoch 68/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.2454 - acc: 0.9271 - val_loss: 0.1618 - val_acc: 0.9429\n",
      "Epoch 69/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.2639 - acc: 0.9170 - val_loss: 0.1570 - val_acc: 0.9444\n",
      "Epoch 70/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2457 - acc: 0.9189 - val_loss: 0.1626 - val_acc: 0.9415\n",
      "Epoch 71/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.2337 - acc: 0.9279 - val_loss: 0.1636 - val_acc: 0.9472\n",
      "Epoch 72/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.2370 - acc: 0.9275 - val_loss: 0.1593 - val_acc: 0.9472\n",
      "Epoch 73/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2511 - acc: 0.9245 - val_loss: 0.1514 - val_acc: 0.9486\n",
      "Epoch 74/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2511 - acc: 0.9219 - val_loss: 0.1636 - val_acc: 0.9458\n",
      "Epoch 75/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2441 - acc: 0.9208 - val_loss: 0.1606 - val_acc: 0.9458\n",
      "Epoch 76/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2310 - acc: 0.9226 - val_loss: 0.1571 - val_acc: 0.9458\n",
      "Epoch 77/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2360 - acc: 0.9253 - val_loss: 0.1562 - val_acc: 0.9444\n",
      "Epoch 78/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2388 - acc: 0.9294 - val_loss: 0.1547 - val_acc: 0.9458\n",
      "Epoch 79/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2324 - acc: 0.9238 - val_loss: 0.1650 - val_acc: 0.9429\n",
      "Epoch 80/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2433 - acc: 0.9249 - val_loss: 0.1500 - val_acc: 0.9458\n",
      "Epoch 81/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2445 - acc: 0.9226 - val_loss: 0.1540 - val_acc: 0.9458\n",
      "Epoch 82/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2419 - acc: 0.9256 - val_loss: 0.1603 - val_acc: 0.9458\n",
      "Epoch 83/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2324 - acc: 0.9268 - val_loss: 0.1612 - val_acc: 0.9415\n",
      "Epoch 84/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2380 - acc: 0.9245 - val_loss: 0.1564 - val_acc: 0.9486\n",
      "Epoch 85/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.2485 - acc: 0.9208 - val_loss: 0.1551 - val_acc: 0.9458\n",
      "Epoch 86/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.2330 - acc: 0.9305 - val_loss: 0.1586 - val_acc: 0.9458\n",
      "Epoch 87/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2195 - acc: 0.9342 - val_loss: 0.1530 - val_acc: 0.9472\n",
      "Epoch 88/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2538 - acc: 0.9152 - val_loss: 0.1571 - val_acc: 0.9415\n",
      "Epoch 89/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2342 - acc: 0.9226 - val_loss: 0.1559 - val_acc: 0.9486\n",
      "Epoch 90/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.2476 - acc: 0.9204 - val_loss: 0.1459 - val_acc: 0.9472\n",
      "Epoch 91/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2390 - acc: 0.9260 - val_loss: 0.1520 - val_acc: 0.9444\n",
      "Epoch 92/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2246 - acc: 0.9283 - val_loss: 0.1507 - val_acc: 0.9472\n",
      "Epoch 93/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2231 - acc: 0.9339 - val_loss: 0.1460 - val_acc: 0.9444\n",
      "Epoch 94/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2466 - acc: 0.9234 - val_loss: 0.1475 - val_acc: 0.9472\n",
      "Epoch 95/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2401 - acc: 0.9234 - val_loss: 0.1508 - val_acc: 0.9458\n",
      "Epoch 96/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2144 - acc: 0.9339 - val_loss: 0.1553 - val_acc: 0.9472\n",
      "Epoch 97/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2321 - acc: 0.9241 - val_loss: 0.1508 - val_acc: 0.9472\n",
      "Epoch 98/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2340 - acc: 0.9238 - val_loss: 0.1466 - val_acc: 0.9515\n",
      "Epoch 99/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2317 - acc: 0.9260 - val_loss: 0.1514 - val_acc: 0.9472\n",
      "Epoch 100/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2184 - acc: 0.9309 - val_loss: 0.1588 - val_acc: 0.9529\n",
      "Epoch 101/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2129 - acc: 0.9290 - val_loss: 0.1511 - val_acc: 0.9486\n",
      "Epoch 102/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2262 - acc: 0.9294 - val_loss: 0.1529 - val_acc: 0.9501\n",
      "Epoch 103/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2267 - acc: 0.9294 - val_loss: 0.1489 - val_acc: 0.9444\n",
      "Epoch 104/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2324 - acc: 0.9245 - val_loss: 0.1509 - val_acc: 0.9501\n",
      "Epoch 105/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2238 - acc: 0.9339 - val_loss: 0.1582 - val_acc: 0.9401\n",
      "Epoch 106/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2236 - acc: 0.9305 - val_loss: 0.1523 - val_acc: 0.9501\n",
      "Epoch 107/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2188 - acc: 0.9324 - val_loss: 0.1559 - val_acc: 0.9444\n",
      "Epoch 108/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2254 - acc: 0.9320 - val_loss: 0.1460 - val_acc: 0.9515\n",
      "Epoch 109/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2033 - acc: 0.9383 - val_loss: 0.1528 - val_acc: 0.9515\n",
      "Epoch 110/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2238 - acc: 0.9279 - val_loss: 0.1470 - val_acc: 0.9486\n",
      "Epoch 111/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2154 - acc: 0.9324 - val_loss: 0.1536 - val_acc: 0.9529\n",
      "Epoch 112/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2147 - acc: 0.9402 - val_loss: 0.1502 - val_acc: 0.9501\n",
      "Epoch 113/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2182 - acc: 0.9383 - val_loss: 0.1553 - val_acc: 0.9444\n",
      "Epoch 114/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2236 - acc: 0.9275 - val_loss: 0.1548 - val_acc: 0.9515\n",
      "Epoch 115/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2113 - acc: 0.9335 - val_loss: 0.1452 - val_acc: 0.9486\n",
      "Epoch 116/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2169 - acc: 0.9312 - val_loss: 0.1416 - val_acc: 0.9515\n",
      "Epoch 117/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2099 - acc: 0.9350 - val_loss: 0.1498 - val_acc: 0.9544\n",
      "Epoch 118/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2074 - acc: 0.9350 - val_loss: 0.1514 - val_acc: 0.9515\n",
      "Epoch 119/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2041 - acc: 0.9372 - val_loss: 0.1510 - val_acc: 0.9486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2014 - acc: 0.9391 - val_loss: 0.1509 - val_acc: 0.9515\n",
      "Epoch 121/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2181 - acc: 0.9368 - val_loss: 0.1518 - val_acc: 0.9486\n",
      "Epoch 122/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.2046 - acc: 0.9395 - val_loss: 0.1559 - val_acc: 0.9486\n",
      "Epoch 123/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2048 - acc: 0.9365 - val_loss: 0.1609 - val_acc: 0.9529\n",
      "Epoch 124/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2077 - acc: 0.9361 - val_loss: 0.1485 - val_acc: 0.9486\n",
      "Epoch 125/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2247 - acc: 0.9331 - val_loss: 0.1484 - val_acc: 0.9429\n",
      "Epoch 126/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2031 - acc: 0.9391 - val_loss: 0.1570 - val_acc: 0.9501\n",
      "Epoch 127/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2220 - acc: 0.9350 - val_loss: 0.1509 - val_acc: 0.9501\n",
      "Epoch 128/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.2156 - acc: 0.9346 - val_loss: 0.1501 - val_acc: 0.9472\n",
      "Epoch 129/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2299 - acc: 0.9335 - val_loss: 0.1389 - val_acc: 0.9472\n",
      "Epoch 130/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2218 - acc: 0.9312 - val_loss: 0.1479 - val_acc: 0.9515\n",
      "Epoch 131/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2139 - acc: 0.9316 - val_loss: 0.1510 - val_acc: 0.9515\n",
      "Epoch 132/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.2142 - acc: 0.9365 - val_loss: 0.1433 - val_acc: 0.9529\n",
      "Epoch 133/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2256 - acc: 0.9301 - val_loss: 0.1501 - val_acc: 0.9529\n",
      "Epoch 134/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2114 - acc: 0.9350 - val_loss: 0.1603 - val_acc: 0.9501\n",
      "Epoch 135/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2121 - acc: 0.9372 - val_loss: 0.1529 - val_acc: 0.9458\n",
      "Epoch 136/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2071 - acc: 0.9368 - val_loss: 0.1596 - val_acc: 0.9515\n",
      "Epoch 137/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2089 - acc: 0.9391 - val_loss: 0.1605 - val_acc: 0.9515\n",
      "Epoch 138/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2043 - acc: 0.9395 - val_loss: 0.1463 - val_acc: 0.9472\n",
      "Epoch 139/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2042 - acc: 0.9413 - val_loss: 0.1486 - val_acc: 0.9472\n",
      "Epoch 140/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2155 - acc: 0.9368 - val_loss: 0.1503 - val_acc: 0.9472\n",
      "Epoch 141/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2099 - acc: 0.9410 - val_loss: 0.1495 - val_acc: 0.9501\n",
      "Epoch 142/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2010 - acc: 0.9372 - val_loss: 0.1516 - val_acc: 0.9501\n",
      "Epoch 143/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2020 - acc: 0.9402 - val_loss: 0.1440 - val_acc: 0.9486\n",
      "Epoch 144/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2012 - acc: 0.9402 - val_loss: 0.1589 - val_acc: 0.9501\n",
      "Epoch 145/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2154 - acc: 0.9331 - val_loss: 0.1468 - val_acc: 0.9501\n",
      "Epoch 146/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1945 - acc: 0.9413 - val_loss: 0.1556 - val_acc: 0.9458\n",
      "Epoch 147/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2072 - acc: 0.9398 - val_loss: 0.1478 - val_acc: 0.9501\n",
      "Epoch 148/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2141 - acc: 0.9380 - val_loss: 0.1452 - val_acc: 0.9529\n",
      "Epoch 149/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2146 - acc: 0.9331 - val_loss: 0.1473 - val_acc: 0.9486\n",
      "Epoch 150/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2133 - acc: 0.9350 - val_loss: 0.1514 - val_acc: 0.9501\n",
      "Epoch 151/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1951 - acc: 0.9421 - val_loss: 0.1471 - val_acc: 0.9472\n",
      "Epoch 152/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2155 - acc: 0.9361 - val_loss: 0.1408 - val_acc: 0.9486\n",
      "Epoch 153/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2245 - acc: 0.9327 - val_loss: 0.1504 - val_acc: 0.9544\n",
      "Epoch 154/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1979 - acc: 0.9443 - val_loss: 0.1613 - val_acc: 0.9529\n",
      "Epoch 155/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1805 - acc: 0.9454 - val_loss: 0.1490 - val_acc: 0.9544\n",
      "Epoch 156/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2162 - acc: 0.9279 - val_loss: 0.1447 - val_acc: 0.9586\n",
      "Epoch 157/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2051 - acc: 0.9350 - val_loss: 0.1584 - val_acc: 0.9515\n",
      "Epoch 158/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1949 - acc: 0.9402 - val_loss: 0.1490 - val_acc: 0.9515\n",
      "Epoch 159/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2108 - acc: 0.9425 - val_loss: 0.1560 - val_acc: 0.9544\n",
      "Epoch 160/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2036 - acc: 0.9391 - val_loss: 0.1489 - val_acc: 0.9515\n",
      "Epoch 161/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1938 - acc: 0.9410 - val_loss: 0.1470 - val_acc: 0.9501\n",
      "Epoch 162/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2222 - acc: 0.9421 - val_loss: 0.1573 - val_acc: 0.9544\n",
      "Epoch 163/500\n",
      "2676/2676 [==============================] - 0s 36us/step - loss: 0.2021 - acc: 0.9410 - val_loss: 0.1506 - val_acc: 0.9558\n",
      "Epoch 164/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2060 - acc: 0.9365 - val_loss: 0.1649 - val_acc: 0.9529\n",
      "Epoch 165/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2142 - acc: 0.9402 - val_loss: 0.1509 - val_acc: 0.9558\n",
      "Epoch 166/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1939 - acc: 0.9454 - val_loss: 0.1423 - val_acc: 0.9558\n",
      "Epoch 167/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2007 - acc: 0.9372 - val_loss: 0.1477 - val_acc: 0.9515\n",
      "Epoch 168/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2046 - acc: 0.9421 - val_loss: 0.1436 - val_acc: 0.9515\n",
      "Epoch 169/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2215 - acc: 0.9324 - val_loss: 0.1491 - val_acc: 0.9572\n",
      "Epoch 170/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1999 - acc: 0.9383 - val_loss: 0.1443 - val_acc: 0.9558\n",
      "Epoch 171/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1916 - acc: 0.9406 - val_loss: 0.1597 - val_acc: 0.9544\n",
      "Epoch 172/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.2007 - acc: 0.9387 - val_loss: 0.1512 - val_acc: 0.9544\n",
      "Epoch 173/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.2049 - acc: 0.9372 - val_loss: 0.1439 - val_acc: 0.9529\n",
      "Epoch 174/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.2107 - acc: 0.9361 - val_loss: 0.1505 - val_acc: 0.9544\n",
      "Epoch 175/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.2201 - acc: 0.9365 - val_loss: 0.1500 - val_acc: 0.9572\n",
      "Epoch 176/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1967 - acc: 0.9357 - val_loss: 0.1631 - val_acc: 0.9529\n",
      "Epoch 177/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2010 - acc: 0.9391 - val_loss: 0.1551 - val_acc: 0.9558\n",
      "Epoch 178/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1870 - acc: 0.9484 - val_loss: 0.1606 - val_acc: 0.9515\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2157 - acc: 0.9380 - val_loss: 0.1460 - val_acc: 0.9515\n",
      "Epoch 180/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1985 - acc: 0.9439 - val_loss: 0.1463 - val_acc: 0.9501\n",
      "Epoch 181/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1957 - acc: 0.9410 - val_loss: 0.1499 - val_acc: 0.9586\n",
      "Epoch 182/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1798 - acc: 0.9469 - val_loss: 0.1469 - val_acc: 0.9558\n",
      "Epoch 183/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.2041 - acc: 0.9421 - val_loss: 0.1474 - val_acc: 0.9515\n",
      "Epoch 184/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1967 - acc: 0.9383 - val_loss: 0.1421 - val_acc: 0.9501\n",
      "Epoch 185/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1943 - acc: 0.9417 - val_loss: 0.1493 - val_acc: 0.9544\n",
      "Epoch 186/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1994 - acc: 0.9421 - val_loss: 0.1387 - val_acc: 0.9544\n",
      "Epoch 187/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1975 - acc: 0.9395 - val_loss: 0.1470 - val_acc: 0.9572\n",
      "Epoch 188/500\n",
      "2676/2676 [==============================] - 0s 55us/step - loss: 0.1772 - acc: 0.9503 - val_loss: 0.1447 - val_acc: 0.9572\n",
      "Epoch 189/500\n",
      "2676/2676 [==============================] - 0s 54us/step - loss: 0.2000 - acc: 0.9417 - val_loss: 0.1488 - val_acc: 0.9558\n",
      "Epoch 190/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1787 - acc: 0.9488 - val_loss: 0.1451 - val_acc: 0.9558\n",
      "Epoch 191/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.2020 - acc: 0.9417 - val_loss: 0.1339 - val_acc: 0.9558\n",
      "Epoch 192/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1873 - acc: 0.9443 - val_loss: 0.1442 - val_acc: 0.9586\n",
      "Epoch 193/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.2046 - acc: 0.9428 - val_loss: 0.1421 - val_acc: 0.9572\n",
      "Epoch 194/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.2074 - acc: 0.9372 - val_loss: 0.1516 - val_acc: 0.9601\n",
      "Epoch 195/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1978 - acc: 0.9402 - val_loss: 0.1404 - val_acc: 0.9615\n",
      "Epoch 196/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1924 - acc: 0.9406 - val_loss: 0.1484 - val_acc: 0.9572\n",
      "Epoch 197/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1695 - acc: 0.9510 - val_loss: 0.1518 - val_acc: 0.9558\n",
      "Epoch 198/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1983 - acc: 0.9376 - val_loss: 0.1419 - val_acc: 0.9586\n",
      "Epoch 199/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1943 - acc: 0.9425 - val_loss: 0.1355 - val_acc: 0.9529\n",
      "Epoch 200/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1959 - acc: 0.9425 - val_loss: 0.1382 - val_acc: 0.9572\n",
      "Epoch 201/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1772 - acc: 0.9507 - val_loss: 0.1420 - val_acc: 0.9558\n",
      "Epoch 202/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.2027 - acc: 0.9368 - val_loss: 0.1363 - val_acc: 0.9586\n",
      "Epoch 203/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1969 - acc: 0.9462 - val_loss: 0.1441 - val_acc: 0.9572\n",
      "Epoch 204/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1746 - acc: 0.9484 - val_loss: 0.1575 - val_acc: 0.9572\n",
      "Epoch 205/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1801 - acc: 0.9439 - val_loss: 0.1465 - val_acc: 0.9529\n",
      "Epoch 206/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1946 - acc: 0.9432 - val_loss: 0.1520 - val_acc: 0.9572\n",
      "Epoch 207/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.2047 - acc: 0.9398 - val_loss: 0.1447 - val_acc: 0.9529\n",
      "Epoch 208/500\n",
      "2676/2676 [==============================] - 0s 96us/step - loss: 0.1889 - acc: 0.9454 - val_loss: 0.1501 - val_acc: 0.9558\n",
      "Epoch 209/500\n",
      "2676/2676 [==============================] - 0s 56us/step - loss: 0.2007 - acc: 0.9391 - val_loss: 0.1474 - val_acc: 0.9558\n",
      "Epoch 210/500\n",
      "2676/2676 [==============================] - 0s 55us/step - loss: 0.1906 - acc: 0.9421 - val_loss: 0.1396 - val_acc: 0.9529\n",
      "Epoch 211/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.1733 - acc: 0.9496 - val_loss: 0.1512 - val_acc: 0.9572\n",
      "Epoch 212/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1737 - acc: 0.9462 - val_loss: 0.1503 - val_acc: 0.9544\n",
      "Epoch 213/500\n",
      "2676/2676 [==============================] - 0s 54us/step - loss: 0.2005 - acc: 0.9436 - val_loss: 0.1326 - val_acc: 0.9558\n",
      "Epoch 214/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1825 - acc: 0.9458 - val_loss: 0.1447 - val_acc: 0.9586\n",
      "Epoch 215/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1895 - acc: 0.9436 - val_loss: 0.1374 - val_acc: 0.9572\n",
      "Epoch 216/500\n",
      "2676/2676 [==============================] - 0s 52us/step - loss: 0.1605 - acc: 0.9548 - val_loss: 0.1598 - val_acc: 0.9572\n",
      "Epoch 217/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1917 - acc: 0.9481 - val_loss: 0.1481 - val_acc: 0.9572\n",
      "Epoch 218/500\n",
      "2676/2676 [==============================] - 0s 57us/step - loss: 0.1637 - acc: 0.9510 - val_loss: 0.1493 - val_acc: 0.9586\n",
      "Epoch 219/500\n",
      "2676/2676 [==============================] - 0s 53us/step - loss: 0.1765 - acc: 0.9484 - val_loss: 0.1421 - val_acc: 0.9572\n",
      "Epoch 220/500\n",
      "2676/2676 [==============================] - 0s 56us/step - loss: 0.1801 - acc: 0.9481 - val_loss: 0.1563 - val_acc: 0.9601\n",
      "Epoch 221/500\n",
      "2676/2676 [==============================] - 0s 68us/step - loss: 0.1565 - acc: 0.9514 - val_loss: 0.1475 - val_acc: 0.9601\n",
      "Epoch 222/500\n",
      "2676/2676 [==============================] - 0s 57us/step - loss: 0.1778 - acc: 0.9533 - val_loss: 0.1484 - val_acc: 0.9586\n",
      "Epoch 223/500\n",
      "2676/2676 [==============================] - 0s 61us/step - loss: 0.1968 - acc: 0.9454 - val_loss: 0.1527 - val_acc: 0.9601\n",
      "Epoch 224/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.1975 - acc: 0.9469 - val_loss: 0.1487 - val_acc: 0.9529\n",
      "Epoch 225/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1926 - acc: 0.9417 - val_loss: 0.1415 - val_acc: 0.9544\n",
      "Epoch 226/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1989 - acc: 0.9406 - val_loss: 0.1416 - val_acc: 0.9544\n",
      "Epoch 227/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.1782 - acc: 0.9518 - val_loss: 0.1523 - val_acc: 0.9558\n",
      "Epoch 228/500\n",
      "2676/2676 [==============================] - 0s 51us/step - loss: 0.1791 - acc: 0.9454 - val_loss: 0.1463 - val_acc: 0.9601\n",
      "Epoch 229/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1817 - acc: 0.9466 - val_loss: 0.1430 - val_acc: 0.9586\n",
      "Epoch 230/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1923 - acc: 0.9447 - val_loss: 0.1504 - val_acc: 0.9572\n",
      "Epoch 231/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1663 - acc: 0.9537 - val_loss: 0.1538 - val_acc: 0.9601\n",
      "Epoch 232/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.1897 - acc: 0.9425 - val_loss: 0.1410 - val_acc: 0.9586\n",
      "Epoch 233/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1944 - acc: 0.9477 - val_loss: 0.1577 - val_acc: 0.9615\n",
      "Epoch 234/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1846 - acc: 0.9462 - val_loss: 0.1528 - val_acc: 0.9558\n",
      "Epoch 235/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1884 - acc: 0.9473 - val_loss: 0.1467 - val_acc: 0.9615\n",
      "Epoch 236/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1893 - acc: 0.9413 - val_loss: 0.1551 - val_acc: 0.9572\n",
      "Epoch 237/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1771 - acc: 0.9462 - val_loss: 0.1602 - val_acc: 0.9572\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1691 - acc: 0.9469 - val_loss: 0.1524 - val_acc: 0.9601\n",
      "Epoch 239/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1600 - acc: 0.9488 - val_loss: 0.1524 - val_acc: 0.9572\n",
      "Epoch 240/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1595 - acc: 0.9492 - val_loss: 0.1833 - val_acc: 0.9572\n",
      "Epoch 241/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1888 - acc: 0.9484 - val_loss: 0.1609 - val_acc: 0.9558\n",
      "Epoch 242/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1891 - acc: 0.9518 - val_loss: 0.1584 - val_acc: 0.9558\n",
      "Epoch 243/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1945 - acc: 0.9462 - val_loss: 0.1440 - val_acc: 0.9586\n",
      "Epoch 244/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1806 - acc: 0.9417 - val_loss: 0.1495 - val_acc: 0.9601\n",
      "Epoch 245/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1865 - acc: 0.9425 - val_loss: 0.1407 - val_acc: 0.9615\n",
      "Epoch 246/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1897 - acc: 0.9432 - val_loss: 0.1519 - val_acc: 0.9601\n",
      "Epoch 247/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1775 - acc: 0.9473 - val_loss: 0.1523 - val_acc: 0.9586\n",
      "Epoch 248/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1647 - acc: 0.9496 - val_loss: 0.1574 - val_acc: 0.9586\n",
      "Epoch 249/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1706 - acc: 0.9496 - val_loss: 0.1442 - val_acc: 0.9572\n",
      "Epoch 250/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1684 - acc: 0.9503 - val_loss: 0.1423 - val_acc: 0.9601\n",
      "Epoch 251/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1756 - acc: 0.9473 - val_loss: 0.1458 - val_acc: 0.9615\n",
      "Epoch 252/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1715 - acc: 0.9473 - val_loss: 0.1444 - val_acc: 0.9629\n",
      "Epoch 253/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1658 - acc: 0.9529 - val_loss: 0.1586 - val_acc: 0.9586\n",
      "Epoch 254/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1611 - acc: 0.9518 - val_loss: 0.1649 - val_acc: 0.9615\n",
      "Epoch 255/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1674 - acc: 0.9496 - val_loss: 0.1422 - val_acc: 0.9615\n",
      "Epoch 256/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1805 - acc: 0.9477 - val_loss: 0.1512 - val_acc: 0.9558\n",
      "Epoch 257/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1838 - acc: 0.9469 - val_loss: 0.1474 - val_acc: 0.9586\n",
      "Epoch 258/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1675 - acc: 0.9481 - val_loss: 0.1617 - val_acc: 0.9572\n",
      "Epoch 259/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1834 - acc: 0.9443 - val_loss: 0.1571 - val_acc: 0.9572\n",
      "Epoch 260/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1795 - acc: 0.9443 - val_loss: 0.1479 - val_acc: 0.9572\n",
      "Epoch 261/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1745 - acc: 0.9462 - val_loss: 0.1489 - val_acc: 0.9572\n",
      "Epoch 262/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1719 - acc: 0.9488 - val_loss: 0.1496 - val_acc: 0.9558\n",
      "Epoch 263/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1765 - acc: 0.9477 - val_loss: 0.1459 - val_acc: 0.9572\n",
      "Epoch 264/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1721 - acc: 0.9492 - val_loss: 0.1564 - val_acc: 0.9544\n",
      "Epoch 265/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1711 - acc: 0.9529 - val_loss: 0.1407 - val_acc: 0.9572\n",
      "Epoch 266/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1633 - acc: 0.9522 - val_loss: 0.1346 - val_acc: 0.9572\n",
      "Epoch 267/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1732 - acc: 0.9510 - val_loss: 0.1534 - val_acc: 0.9572\n",
      "Epoch 268/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1769 - acc: 0.9492 - val_loss: 0.1484 - val_acc: 0.9572\n",
      "Epoch 269/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1674 - acc: 0.9458 - val_loss: 0.1507 - val_acc: 0.9558\n",
      "Epoch 270/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1796 - acc: 0.9466 - val_loss: 0.1439 - val_acc: 0.9586\n",
      "Epoch 271/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1699 - acc: 0.9492 - val_loss: 0.1467 - val_acc: 0.9529\n",
      "Epoch 272/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1717 - acc: 0.9503 - val_loss: 0.1528 - val_acc: 0.9558\n",
      "Epoch 273/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1945 - acc: 0.9469 - val_loss: 0.1534 - val_acc: 0.9544\n",
      "Epoch 274/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1801 - acc: 0.9439 - val_loss: 0.1418 - val_acc: 0.9572\n",
      "Epoch 275/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.1703 - acc: 0.9529 - val_loss: 0.1464 - val_acc: 0.9544\n",
      "Epoch 276/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1748 - acc: 0.9522 - val_loss: 0.1360 - val_acc: 0.9601\n",
      "Epoch 277/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1781 - acc: 0.9473 - val_loss: 0.1379 - val_acc: 0.9629\n",
      "Epoch 278/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1738 - acc: 0.9514 - val_loss: 0.1443 - val_acc: 0.9615\n",
      "Epoch 279/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1658 - acc: 0.9518 - val_loss: 0.1478 - val_acc: 0.9615\n",
      "Epoch 280/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1637 - acc: 0.9555 - val_loss: 0.1353 - val_acc: 0.9629\n",
      "Epoch 281/500\n",
      "2676/2676 [==============================] - 0s 55us/step - loss: 0.1692 - acc: 0.9496 - val_loss: 0.1426 - val_acc: 0.9601\n",
      "Epoch 282/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1814 - acc: 0.9454 - val_loss: 0.1531 - val_acc: 0.9601\n",
      "Epoch 283/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1636 - acc: 0.9570 - val_loss: 0.1563 - val_acc: 0.9615\n",
      "Epoch 284/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1835 - acc: 0.9469 - val_loss: 0.1566 - val_acc: 0.9558\n",
      "Epoch 285/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1727 - acc: 0.9466 - val_loss: 0.1439 - val_acc: 0.9615\n",
      "Epoch 286/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1653 - acc: 0.9510 - val_loss: 0.1454 - val_acc: 0.9586\n",
      "Epoch 287/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1710 - acc: 0.9488 - val_loss: 0.1542 - val_acc: 0.9586\n",
      "Epoch 288/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1683 - acc: 0.9488 - val_loss: 0.1448 - val_acc: 0.9615\n",
      "Epoch 289/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1381 - acc: 0.9626 - val_loss: 0.1574 - val_acc: 0.9586\n",
      "Epoch 290/500\n",
      "2676/2676 [==============================] - 0s 55us/step - loss: 0.1606 - acc: 0.9510 - val_loss: 0.1554 - val_acc: 0.9615\n",
      "Epoch 291/500\n",
      "2676/2676 [==============================] - 0s 51us/step - loss: 0.1457 - acc: 0.9581 - val_loss: 0.1525 - val_acc: 0.9615\n",
      "Epoch 292/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1691 - acc: 0.9481 - val_loss: 0.1623 - val_acc: 0.9572\n",
      "Epoch 293/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1682 - acc: 0.9529 - val_loss: 0.1601 - val_acc: 0.9544\n",
      "Epoch 294/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1569 - acc: 0.9544 - val_loss: 0.1504 - val_acc: 0.9572\n",
      "Epoch 295/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1587 - acc: 0.9507 - val_loss: 0.1474 - val_acc: 0.9629\n",
      "Epoch 296/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1734 - acc: 0.9488 - val_loss: 0.1577 - val_acc: 0.9615\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1624 - acc: 0.9510 - val_loss: 0.1649 - val_acc: 0.9615\n",
      "Epoch 298/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1746 - acc: 0.9492 - val_loss: 0.1455 - val_acc: 0.9586\n",
      "Epoch 299/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1617 - acc: 0.9525 - val_loss: 0.1564 - val_acc: 0.9558\n",
      "Epoch 300/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1667 - acc: 0.9552 - val_loss: 0.1570 - val_acc: 0.9601\n",
      "Epoch 301/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1685 - acc: 0.9503 - val_loss: 0.1349 - val_acc: 0.9615\n",
      "Epoch 302/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1513 - acc: 0.9581 - val_loss: 0.1539 - val_acc: 0.9601\n",
      "Epoch 303/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1869 - acc: 0.9436 - val_loss: 0.1411 - val_acc: 0.9601\n",
      "Epoch 304/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1665 - acc: 0.9559 - val_loss: 0.1613 - val_acc: 0.9601\n",
      "Epoch 305/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1685 - acc: 0.9484 - val_loss: 0.1529 - val_acc: 0.9601\n",
      "Epoch 306/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1606 - acc: 0.9522 - val_loss: 0.1846 - val_acc: 0.9572\n",
      "Epoch 307/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1927 - acc: 0.9484 - val_loss: 0.1430 - val_acc: 0.9558\n",
      "Epoch 308/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1734 - acc: 0.9496 - val_loss: 0.1444 - val_acc: 0.9586\n",
      "Epoch 309/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1503 - acc: 0.9540 - val_loss: 0.1581 - val_acc: 0.9586\n",
      "Epoch 310/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1451 - acc: 0.9555 - val_loss: 0.1684 - val_acc: 0.9572\n",
      "Epoch 311/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1681 - acc: 0.9533 - val_loss: 0.1467 - val_acc: 0.9629\n",
      "Epoch 312/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1510 - acc: 0.9548 - val_loss: 0.1530 - val_acc: 0.9586\n",
      "Epoch 313/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1634 - acc: 0.9548 - val_loss: 0.1465 - val_acc: 0.9586\n",
      "Epoch 314/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1583 - acc: 0.9604 - val_loss: 0.1479 - val_acc: 0.9615\n",
      "Epoch 315/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1558 - acc: 0.9525 - val_loss: 0.1495 - val_acc: 0.9615\n",
      "Epoch 316/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1635 - acc: 0.9533 - val_loss: 0.1416 - val_acc: 0.9601\n",
      "Epoch 317/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1527 - acc: 0.9525 - val_loss: 0.1449 - val_acc: 0.9615\n",
      "Epoch 318/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1644 - acc: 0.9473 - val_loss: 0.1505 - val_acc: 0.9658\n",
      "Epoch 319/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1544 - acc: 0.9578 - val_loss: 0.1568 - val_acc: 0.9615\n",
      "Epoch 320/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1666 - acc: 0.9488 - val_loss: 0.1536 - val_acc: 0.9629\n",
      "Epoch 321/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1699 - acc: 0.9518 - val_loss: 0.1412 - val_acc: 0.9615\n",
      "Epoch 322/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1653 - acc: 0.9518 - val_loss: 0.1413 - val_acc: 0.9601\n",
      "Epoch 323/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1868 - acc: 0.9428 - val_loss: 0.1440 - val_acc: 0.9615\n",
      "Epoch 324/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1807 - acc: 0.9488 - val_loss: 0.1446 - val_acc: 0.9629\n",
      "Epoch 325/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1637 - acc: 0.9529 - val_loss: 0.1524 - val_acc: 0.9586\n",
      "Epoch 326/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1643 - acc: 0.9563 - val_loss: 0.1555 - val_acc: 0.9601\n",
      "Epoch 327/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1605 - acc: 0.9544 - val_loss: 0.1472 - val_acc: 0.9615\n",
      "Epoch 328/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1848 - acc: 0.9458 - val_loss: 0.1426 - val_acc: 0.9629\n",
      "Epoch 329/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1639 - acc: 0.9548 - val_loss: 0.1514 - val_acc: 0.9586\n",
      "Epoch 330/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1729 - acc: 0.9522 - val_loss: 0.1412 - val_acc: 0.9601\n",
      "Epoch 331/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.1476 - acc: 0.9570 - val_loss: 0.1500 - val_acc: 0.9615\n",
      "Epoch 332/500\n",
      "2676/2676 [==============================] - 0s 51us/step - loss: 0.1617 - acc: 0.9522 - val_loss: 0.1427 - val_acc: 0.9629\n",
      "Epoch 333/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1601 - acc: 0.9499 - val_loss: 0.1496 - val_acc: 0.9615\n",
      "Epoch 334/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1545 - acc: 0.9529 - val_loss: 0.1596 - val_acc: 0.9586\n",
      "Epoch 335/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1562 - acc: 0.9567 - val_loss: 0.1498 - val_acc: 0.9615\n",
      "Epoch 336/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1486 - acc: 0.9567 - val_loss: 0.1363 - val_acc: 0.9643\n",
      "Epoch 337/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1745 - acc: 0.9496 - val_loss: 0.1322 - val_acc: 0.9643\n",
      "Epoch 338/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1543 - acc: 0.9525 - val_loss: 0.1390 - val_acc: 0.9643\n",
      "Epoch 339/500\n",
      "2676/2676 [==============================] - 0s 50us/step - loss: 0.1609 - acc: 0.9529 - val_loss: 0.1424 - val_acc: 0.9629\n",
      "Epoch 340/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1514 - acc: 0.9589 - val_loss: 0.1478 - val_acc: 0.9601\n",
      "Epoch 341/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1519 - acc: 0.9548 - val_loss: 0.1377 - val_acc: 0.9615\n",
      "Epoch 342/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1752 - acc: 0.9529 - val_loss: 0.1367 - val_acc: 0.9629\n",
      "Epoch 343/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1834 - acc: 0.9462 - val_loss: 0.1549 - val_acc: 0.9572\n",
      "Epoch 344/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1570 - acc: 0.9499 - val_loss: 0.1569 - val_acc: 0.9601\n",
      "Epoch 345/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1741 - acc: 0.9510 - val_loss: 0.1608 - val_acc: 0.9601\n",
      "Epoch 346/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1664 - acc: 0.9514 - val_loss: 0.1732 - val_acc: 0.9615\n",
      "Epoch 347/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1737 - acc: 0.9481 - val_loss: 0.1600 - val_acc: 0.9586\n",
      "Epoch 348/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1599 - acc: 0.9522 - val_loss: 0.1543 - val_acc: 0.9601\n",
      "Epoch 349/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1585 - acc: 0.9544 - val_loss: 0.1458 - val_acc: 0.9586\n",
      "Epoch 350/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1609 - acc: 0.9525 - val_loss: 0.1492 - val_acc: 0.9615\n",
      "Epoch 351/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1671 - acc: 0.9518 - val_loss: 0.1608 - val_acc: 0.9586\n",
      "Epoch 352/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1566 - acc: 0.9537 - val_loss: 0.1592 - val_acc: 0.9558\n",
      "Epoch 353/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1703 - acc: 0.9525 - val_loss: 0.1400 - val_acc: 0.9586\n",
      "Epoch 354/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1561 - acc: 0.9552 - val_loss: 0.1615 - val_acc: 0.9586\n",
      "Epoch 355/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1570 - acc: 0.9581 - val_loss: 0.1584 - val_acc: 0.9601\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1706 - acc: 0.9552 - val_loss: 0.1357 - val_acc: 0.9601\n",
      "Epoch 357/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1608 - acc: 0.9574 - val_loss: 0.1459 - val_acc: 0.9601\n",
      "Epoch 358/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1555 - acc: 0.9533 - val_loss: 0.1447 - val_acc: 0.9601\n",
      "Epoch 359/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1582 - acc: 0.9477 - val_loss: 0.1504 - val_acc: 0.9629\n",
      "Epoch 360/500\n",
      "2676/2676 [==============================] - 0s 48us/step - loss: 0.1830 - acc: 0.9503 - val_loss: 0.1518 - val_acc: 0.9615\n",
      "Epoch 361/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1568 - acc: 0.9544 - val_loss: 0.1441 - val_acc: 0.9615\n",
      "Epoch 362/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1625 - acc: 0.9503 - val_loss: 0.1504 - val_acc: 0.9615\n",
      "Epoch 363/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1649 - acc: 0.9537 - val_loss: 0.1510 - val_acc: 0.9629\n",
      "Epoch 364/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1575 - acc: 0.9552 - val_loss: 0.1357 - val_acc: 0.9615\n",
      "Epoch 365/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1698 - acc: 0.9510 - val_loss: 0.1399 - val_acc: 0.9615\n",
      "Epoch 366/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1522 - acc: 0.9510 - val_loss: 0.1418 - val_acc: 0.9629\n",
      "Epoch 367/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1722 - acc: 0.9514 - val_loss: 0.1463 - val_acc: 0.9643\n",
      "Epoch 368/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1511 - acc: 0.9585 - val_loss: 0.1450 - val_acc: 0.9629\n",
      "Epoch 369/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1700 - acc: 0.9514 - val_loss: 0.1455 - val_acc: 0.9629\n",
      "Epoch 370/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1676 - acc: 0.9481 - val_loss: 0.1497 - val_acc: 0.9643\n",
      "Epoch 371/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1590 - acc: 0.9570 - val_loss: 0.1624 - val_acc: 0.9629\n",
      "Epoch 372/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1495 - acc: 0.9563 - val_loss: 0.1434 - val_acc: 0.9615\n",
      "Epoch 373/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1505 - acc: 0.9563 - val_loss: 0.1471 - val_acc: 0.9629\n",
      "Epoch 374/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1720 - acc: 0.9492 - val_loss: 0.1492 - val_acc: 0.9558\n",
      "Epoch 375/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1574 - acc: 0.9548 - val_loss: 0.1455 - val_acc: 0.9629\n",
      "Epoch 376/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.1496 - acc: 0.9563 - val_loss: 0.1591 - val_acc: 0.9601\n",
      "Epoch 377/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1824 - acc: 0.9447 - val_loss: 0.1454 - val_acc: 0.9629\n",
      "Epoch 378/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1430 - acc: 0.9567 - val_loss: 0.1565 - val_acc: 0.9629\n",
      "Epoch 379/500\n",
      "2676/2676 [==============================] - 0s 80us/step - loss: 0.1591 - acc: 0.9559 - val_loss: 0.1670 - val_acc: 0.9629\n",
      "Epoch 380/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1620 - acc: 0.9548 - val_loss: 0.1626 - val_acc: 0.9643\n",
      "Epoch 381/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1343 - acc: 0.9567 - val_loss: 0.1641 - val_acc: 0.9629\n",
      "Epoch 382/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1602 - acc: 0.9552 - val_loss: 0.1495 - val_acc: 0.9615\n",
      "Epoch 383/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1562 - acc: 0.9578 - val_loss: 0.1706 - val_acc: 0.9629\n",
      "Epoch 384/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1514 - acc: 0.9589 - val_loss: 0.1351 - val_acc: 0.9643\n",
      "Epoch 385/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1529 - acc: 0.9555 - val_loss: 0.1510 - val_acc: 0.9643\n",
      "Epoch 386/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1609 - acc: 0.9559 - val_loss: 0.1477 - val_acc: 0.9629\n",
      "Epoch 387/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1496 - acc: 0.9548 - val_loss: 0.1514 - val_acc: 0.9629\n",
      "Epoch 388/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1522 - acc: 0.9574 - val_loss: 0.1542 - val_acc: 0.9601\n",
      "Epoch 389/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1409 - acc: 0.9570 - val_loss: 0.1501 - val_acc: 0.9629\n",
      "Epoch 390/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1527 - acc: 0.9540 - val_loss: 0.1466 - val_acc: 0.9629\n",
      "Epoch 391/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1594 - acc: 0.9600 - val_loss: 0.1698 - val_acc: 0.9629\n",
      "Epoch 392/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1542 - acc: 0.9525 - val_loss: 0.1435 - val_acc: 0.9615\n",
      "Epoch 393/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1701 - acc: 0.9481 - val_loss: 0.1491 - val_acc: 0.9615\n",
      "Epoch 394/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1553 - acc: 0.9559 - val_loss: 0.1414 - val_acc: 0.9615\n",
      "Epoch 395/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1655 - acc: 0.9499 - val_loss: 0.1404 - val_acc: 0.9615\n",
      "Epoch 396/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1477 - acc: 0.9578 - val_loss: 0.1531 - val_acc: 0.9643\n",
      "Epoch 397/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1473 - acc: 0.9544 - val_loss: 0.1524 - val_acc: 0.9629\n",
      "Epoch 398/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1539 - acc: 0.9537 - val_loss: 0.1605 - val_acc: 0.9601\n",
      "Epoch 399/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1613 - acc: 0.9518 - val_loss: 0.1554 - val_acc: 0.9544\n",
      "Epoch 400/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1391 - acc: 0.9578 - val_loss: 0.1533 - val_acc: 0.9586\n",
      "Epoch 401/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1510 - acc: 0.9604 - val_loss: 0.1662 - val_acc: 0.9586\n",
      "Epoch 402/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1365 - acc: 0.9593 - val_loss: 0.1586 - val_acc: 0.9601\n",
      "Epoch 403/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1725 - acc: 0.9510 - val_loss: 0.1541 - val_acc: 0.9601\n",
      "Epoch 404/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1544 - acc: 0.9537 - val_loss: 0.1387 - val_acc: 0.9615\n",
      "Epoch 405/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1697 - acc: 0.9507 - val_loss: 0.1387 - val_acc: 0.9643\n",
      "Epoch 406/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1666 - acc: 0.9540 - val_loss: 0.1486 - val_acc: 0.9586\n",
      "Epoch 407/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1473 - acc: 0.9589 - val_loss: 0.1543 - val_acc: 0.9629\n",
      "Epoch 408/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1584 - acc: 0.9559 - val_loss: 0.1542 - val_acc: 0.9601\n",
      "Epoch 409/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1528 - acc: 0.9544 - val_loss: 0.1449 - val_acc: 0.9615\n",
      "Epoch 410/500\n",
      "2676/2676 [==============================] - 0s 58us/step - loss: 0.1575 - acc: 0.9548 - val_loss: 0.1394 - val_acc: 0.9643\n",
      "Epoch 411/500\n",
      "2676/2676 [==============================] - 0s 73us/step - loss: 0.1562 - acc: 0.9585 - val_loss: 0.1470 - val_acc: 0.9615\n",
      "Epoch 412/500\n",
      "2676/2676 [==============================] - 0s 61us/step - loss: 0.1744 - acc: 0.9484 - val_loss: 0.1537 - val_acc: 0.9615\n",
      "Epoch 413/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1574 - acc: 0.9522 - val_loss: 0.1485 - val_acc: 0.9601\n",
      "Epoch 414/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1555 - acc: 0.9548 - val_loss: 0.1644 - val_acc: 0.9629\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1494 - acc: 0.9537 - val_loss: 0.1592 - val_acc: 0.9601\n",
      "Epoch 416/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1516 - acc: 0.9600 - val_loss: 0.1612 - val_acc: 0.9629\n",
      "Epoch 417/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1540 - acc: 0.9522 - val_loss: 0.1487 - val_acc: 0.9629\n",
      "Epoch 418/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1666 - acc: 0.9533 - val_loss: 0.1355 - val_acc: 0.9615\n",
      "Epoch 419/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1670 - acc: 0.9529 - val_loss: 0.1545 - val_acc: 0.9601\n",
      "Epoch 420/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1398 - acc: 0.9567 - val_loss: 0.1588 - val_acc: 0.9629\n",
      "Epoch 421/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1432 - acc: 0.9544 - val_loss: 0.1509 - val_acc: 0.9615\n",
      "Epoch 422/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1546 - acc: 0.9533 - val_loss: 0.1539 - val_acc: 0.9643\n",
      "Epoch 423/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1291 - acc: 0.9656 - val_loss: 0.1588 - val_acc: 0.9643\n",
      "Epoch 424/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1487 - acc: 0.9570 - val_loss: 0.1653 - val_acc: 0.9615\n",
      "Epoch 425/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1678 - acc: 0.9507 - val_loss: 0.1505 - val_acc: 0.9629\n",
      "Epoch 426/500\n",
      "2676/2676 [==============================] - 0s 37us/step - loss: 0.1383 - acc: 0.9570 - val_loss: 0.1706 - val_acc: 0.9586\n",
      "Epoch 427/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1705 - acc: 0.9533 - val_loss: 0.1678 - val_acc: 0.9586\n",
      "Epoch 428/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1483 - acc: 0.9574 - val_loss: 0.1696 - val_acc: 0.9615\n",
      "Epoch 429/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1463 - acc: 0.9574 - val_loss: 0.1430 - val_acc: 0.9615\n",
      "Epoch 430/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1479 - acc: 0.9567 - val_loss: 0.1524 - val_acc: 0.9615\n",
      "Epoch 431/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1494 - acc: 0.9604 - val_loss: 0.1615 - val_acc: 0.9601\n",
      "Epoch 432/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1488 - acc: 0.9581 - val_loss: 0.1544 - val_acc: 0.9643\n",
      "Epoch 433/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1451 - acc: 0.9593 - val_loss: 0.1548 - val_acc: 0.9643\n",
      "Epoch 434/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1548 - acc: 0.9559 - val_loss: 0.1573 - val_acc: 0.9615\n",
      "Epoch 435/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1375 - acc: 0.9585 - val_loss: 0.1652 - val_acc: 0.9643\n",
      "Epoch 436/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1319 - acc: 0.9589 - val_loss: 0.1651 - val_acc: 0.9629\n",
      "Epoch 437/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1518 - acc: 0.9600 - val_loss: 0.1633 - val_acc: 0.9643\n",
      "Epoch 438/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1627 - acc: 0.9552 - val_loss: 0.1359 - val_acc: 0.9615\n",
      "Epoch 439/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1529 - acc: 0.9555 - val_loss: 0.1374 - val_acc: 0.9615\n",
      "Epoch 440/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1525 - acc: 0.9559 - val_loss: 0.1639 - val_acc: 0.9629\n",
      "Epoch 441/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1488 - acc: 0.9529 - val_loss: 0.1499 - val_acc: 0.9615\n",
      "Epoch 442/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1436 - acc: 0.9555 - val_loss: 0.1647 - val_acc: 0.9586\n",
      "Epoch 443/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1534 - acc: 0.9559 - val_loss: 0.1513 - val_acc: 0.9615\n",
      "Epoch 444/500\n",
      "2676/2676 [==============================] - 0s 45us/step - loss: 0.1389 - acc: 0.9604 - val_loss: 0.1558 - val_acc: 0.9601\n",
      "Epoch 445/500\n",
      "2676/2676 [==============================] - 0s 47us/step - loss: 0.1582 - acc: 0.9544 - val_loss: 0.1705 - val_acc: 0.9586\n",
      "Epoch 446/500\n",
      "2676/2676 [==============================] - 0s 53us/step - loss: 0.1210 - acc: 0.9615 - val_loss: 0.1727 - val_acc: 0.9586\n",
      "Epoch 447/500\n",
      "2676/2676 [==============================] - 0s 57us/step - loss: 0.1417 - acc: 0.9563 - val_loss: 0.1601 - val_acc: 0.9629\n",
      "Epoch 448/500\n",
      "2676/2676 [==============================] - 0s 58us/step - loss: 0.1352 - acc: 0.9615 - val_loss: 0.1641 - val_acc: 0.9629\n",
      "Epoch 449/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1467 - acc: 0.9552 - val_loss: 0.1555 - val_acc: 0.9615\n",
      "Epoch 450/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1490 - acc: 0.9585 - val_loss: 0.1743 - val_acc: 0.9615\n",
      "Epoch 451/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1438 - acc: 0.9555 - val_loss: 0.1597 - val_acc: 0.9615\n",
      "Epoch 452/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1444 - acc: 0.9555 - val_loss: 0.1659 - val_acc: 0.9586\n",
      "Epoch 453/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1770 - acc: 0.9578 - val_loss: 0.1492 - val_acc: 0.9629\n",
      "Epoch 454/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1424 - acc: 0.9589 - val_loss: 0.1519 - val_acc: 0.9586\n",
      "Epoch 455/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1465 - acc: 0.9496 - val_loss: 0.1699 - val_acc: 0.9629\n",
      "Epoch 456/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1541 - acc: 0.9581 - val_loss: 0.1702 - val_acc: 0.9615\n",
      "Epoch 457/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1398 - acc: 0.9593 - val_loss: 0.1517 - val_acc: 0.9643\n",
      "Epoch 458/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1407 - acc: 0.9574 - val_loss: 0.1596 - val_acc: 0.9643\n",
      "Epoch 459/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1600 - acc: 0.9570 - val_loss: 0.1556 - val_acc: 0.9629\n",
      "Epoch 460/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1540 - acc: 0.9537 - val_loss: 0.1487 - val_acc: 0.9629\n",
      "Epoch 461/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1524 - acc: 0.9529 - val_loss: 0.1564 - val_acc: 0.9643\n",
      "Epoch 462/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1351 - acc: 0.9596 - val_loss: 0.1605 - val_acc: 0.9643\n",
      "Epoch 463/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1421 - acc: 0.9567 - val_loss: 0.1605 - val_acc: 0.9601\n",
      "Epoch 464/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1451 - acc: 0.9596 - val_loss: 0.1797 - val_acc: 0.9601\n",
      "Epoch 465/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1333 - acc: 0.9608 - val_loss: 0.1483 - val_acc: 0.9643\n",
      "Epoch 466/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1555 - acc: 0.9510 - val_loss: 0.1532 - val_acc: 0.9658\n",
      "Epoch 467/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1607 - acc: 0.9596 - val_loss: 0.1534 - val_acc: 0.9672\n",
      "Epoch 468/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1428 - acc: 0.9578 - val_loss: 0.1471 - val_acc: 0.9643\n",
      "Epoch 469/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1313 - acc: 0.9574 - val_loss: 0.1593 - val_acc: 0.9643\n",
      "Epoch 470/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1461 - acc: 0.9544 - val_loss: 0.1519 - val_acc: 0.9643\n",
      "Epoch 471/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1554 - acc: 0.9600 - val_loss: 0.1615 - val_acc: 0.9615\n",
      "Epoch 472/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1599 - acc: 0.9548 - val_loss: 0.1482 - val_acc: 0.9643\n",
      "Epoch 473/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1586 - acc: 0.9510 - val_loss: 0.1439 - val_acc: 0.9629\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1456 - acc: 0.9593 - val_loss: 0.1534 - val_acc: 0.9643\n",
      "Epoch 475/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1398 - acc: 0.9581 - val_loss: 0.1517 - val_acc: 0.9643\n",
      "Epoch 476/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1239 - acc: 0.9664 - val_loss: 0.1671 - val_acc: 0.9629\n",
      "Epoch 477/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1498 - acc: 0.9563 - val_loss: 0.1536 - val_acc: 0.9658\n",
      "Epoch 478/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1491 - acc: 0.9552 - val_loss: 0.1441 - val_acc: 0.9643\n",
      "Epoch 479/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1213 - acc: 0.9626 - val_loss: 0.1495 - val_acc: 0.9629\n",
      "Epoch 480/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1270 - acc: 0.9675 - val_loss: 0.1504 - val_acc: 0.9629\n",
      "Epoch 481/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1481 - acc: 0.9604 - val_loss: 0.1506 - val_acc: 0.9615\n",
      "Epoch 482/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1386 - acc: 0.9634 - val_loss: 0.1699 - val_acc: 0.9629\n",
      "Epoch 483/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1661 - acc: 0.9585 - val_loss: 0.1563 - val_acc: 0.9643\n",
      "Epoch 484/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1581 - acc: 0.9567 - val_loss: 0.1581 - val_acc: 0.9643\n",
      "Epoch 485/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1484 - acc: 0.9578 - val_loss: 0.1557 - val_acc: 0.9643\n",
      "Epoch 486/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1502 - acc: 0.9596 - val_loss: 0.1568 - val_acc: 0.9643\n",
      "Epoch 487/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1437 - acc: 0.9589 - val_loss: 0.1569 - val_acc: 0.9629\n",
      "Epoch 488/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1434 - acc: 0.9570 - val_loss: 0.1606 - val_acc: 0.9601\n",
      "Epoch 489/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1442 - acc: 0.9522 - val_loss: 0.1323 - val_acc: 0.9629\n",
      "Epoch 490/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1570 - acc: 0.9604 - val_loss: 0.1507 - val_acc: 0.9615\n",
      "Epoch 491/500\n",
      "2676/2676 [==============================] - 0s 46us/step - loss: 0.1283 - acc: 0.9645 - val_loss: 0.1611 - val_acc: 0.9615\n",
      "Epoch 492/500\n",
      "2676/2676 [==============================] - 0s 49us/step - loss: 0.1342 - acc: 0.9600 - val_loss: 0.1590 - val_acc: 0.9629\n",
      "Epoch 493/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1830 - acc: 0.9510 - val_loss: 0.1512 - val_acc: 0.9629\n",
      "Epoch 494/500\n",
      "2676/2676 [==============================] - 0s 44us/step - loss: 0.1493 - acc: 0.9563 - val_loss: 0.1700 - val_acc: 0.9601\n",
      "Epoch 495/500\n",
      "2676/2676 [==============================] - 0s 42us/step - loss: 0.1457 - acc: 0.9611 - val_loss: 0.1781 - val_acc: 0.9615\n",
      "Epoch 496/500\n",
      "2676/2676 [==============================] - 0s 41us/step - loss: 0.1596 - acc: 0.9581 - val_loss: 0.1467 - val_acc: 0.9643\n",
      "Epoch 497/500\n",
      "2676/2676 [==============================] - 0s 40us/step - loss: 0.1436 - acc: 0.9611 - val_loss: 0.1598 - val_acc: 0.9629\n",
      "Epoch 498/500\n",
      "2676/2676 [==============================] - 0s 38us/step - loss: 0.1620 - acc: 0.9510 - val_loss: 0.1539 - val_acc: 0.9643\n",
      "Epoch 499/500\n",
      "2676/2676 [==============================] - 0s 43us/step - loss: 0.1568 - acc: 0.9563 - val_loss: 0.1557 - val_acc: 0.9615\n",
      "Epoch 500/500\n",
      "2676/2676 [==============================] - 0s 39us/step - loss: 0.1448 - acc: 0.9585 - val_loss: 0.1514 - val_acc: 0.9643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_norm, Y_train, validation_data=(X_test_norm, Y_test), epochs=500, batch_size=32, verbose=1)#, callbacks= [earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d6cbeee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "model.save('pose_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated pose:\n",
      "STANDING: \t0.010681387\n",
      "BENDING: \t0.0031541495\n",
      "CROUCHING: \t0.9861645\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d6e7abda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing on single example\n",
    "LABELS = [\"STANDING\", \"BENDING\", \"CROUCHING\"]\n",
    "\n",
    "X_sample = load_X('dataset/X_sample.txt')\n",
    "X_sample_norm = norm_X(X_sample)\n",
    "y_out = model.predict(X_sample_norm[0].reshape(1, 36))\n",
    "\n",
    "print(\"Estimated pose:\")\n",
    "for idx in range(len(LABELS)):\n",
    "    print(LABELS[idx] + \": \\t\" + str(y_out[0][idx]))\n",
    "plot(X_sample[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
